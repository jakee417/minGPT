{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af000664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 32\n",
    "T = 10\n",
    "vocab_size = 255\n",
    "C = 32\n",
    "n_head = 4\n",
    "hs = C // n_head\n",
    "assert C % n_head == 0\n",
    "hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a48a0",
   "metadata": {},
   "source": [
    "Transformer\n",
    "\n",
    "<img src=\"transformer.jpg\" width=\"300px\">\n",
    "\n",
    "$\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283c05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "wte = nn.Embedding(vocab_size, C)\n",
    "wpe = nn.Embedding(T, C)\n",
    "\n",
    "# Transformer\n",
    "transformer_dropout = nn.Dropout(0.2)\n",
    "transformer_norm = nn.LayerNorm(C)\n",
    "transformer_fc = nn.Linear(C, vocab_size)\n",
    "\n",
    "# Block\n",
    "block_norm_1 = nn.LayerNorm(C)\n",
    "block_norm_2 = nn.LayerNorm(C)\n",
    "block_fc = nn.Linear(C, 4 * C)\n",
    "block_act = nn.ReLU()\n",
    "block_proj = nn.Linear(4 * C, C)\n",
    "block_dropout = nn.Dropout(0.2)\n",
    "\n",
    "# Attention\n",
    "c_attn = nn.Linear(C, 3 * C)\n",
    "attn_dropout = nn.Dropout(0.2)\n",
    "mask = torch.tril(torch.ones((1, 1, T, T)))\n",
    "c_proj = nn.Linear(C, C)\n",
    "resid_dropout = nn.Dropout(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ffadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw input tokens\n",
    "x = torch.randint(low=0, high=vocab_size, size=(B, T))\n",
    "assert x.shape == (B, T)\n",
    "# Positions of input tokens\n",
    "p = torch.arange(0, T, dtype=torch.long).view(1, T)\n",
    "assert p.shape == (1, T)\n",
    "# Token embeddings\n",
    "x = wte(x)\n",
    "assert x.shape == (B, T, C)\n",
    "# Positional embeddings\n",
    "p = wpe(p)\n",
    "assert p.shape == (1, T, C)\n",
    "# Combine token and positional embeddings w/ broadcast\n",
    "x += p\n",
    "# transformer level dropout\n",
    "x = transformer_dropout(x)\n",
    "assert x.shape == (B, T, C)\n",
    "# attention residual pathway\n",
    "y = x.clone()\n",
    "# Attention layer norm\n",
    "x = block_norm_1(x)\n",
    "# Attention projection\n",
    "x = c_attn(x)\n",
    "assert x.shape == (B, T, 3 * C)\n",
    "# Split attention into key, query, and value tensors\n",
    "k, q, v = x.split(C, dim=2)\n",
    "assert k.shape == (B, T, C)\n",
    "assert q.shape == (B, T, C)\n",
    "assert v.shape == (B, T, C)\n",
    "# Introduce a head size \"batch\"\n",
    "k = k.view(B, T, n_head, C // n_head).transpose(1, 2)\n",
    "q = q.view(B, T, n_head, C // n_head).transpose(1, 2)\n",
    "v = v.view(B, T, n_head, C // n_head).transpose(1, 2)\n",
    "assert k.shape == (B, n_head, T, hs)\n",
    "assert q.shape == (B, n_head, T, hs)\n",
    "assert v.shape == (B, n_head, T, hs)\n",
    "# Compute attention\n",
    "x = q @ k.transpose(-2, -1) * k.size(-1) ** -0.5\n",
    "assert x.shape == (B, n_head, T, T)\n",
    "# Apply the masking for casual self attention\n",
    "x = torch.masked_fill(x, mask == 0, -float('inf'))\n",
    "# Take the softmax to normalize each head\n",
    "x = F.softmax(x, dim=-1)\n",
    "assert torch.allclose(x.sum(-1), torch.ones(B, n_head, T))\n",
    "# Randomly drop nodes communication\n",
    "x = attn_dropout(x)\n",
    "# Apply attention to values\n",
    "x = x @ v\n",
    "assert x.shape == (B, n_head, T, hs)\n",
    "x = x.transpose(1, 2).contiguous().view(B, T, C)\n",
    "assert x.shape == (B, T, C)\n",
    "x = c_proj(x)\n",
    "assert x.shape == (B, T, C)\n",
    "x = resid_dropout(x)\n",
    "x += y.clone()\n",
    "# mlp residual pathway\n",
    "y = x\n",
    "# mlp\n",
    "x = block_norm_2(x)\n",
    "x = block_fc(x)\n",
    "x = block_act(x)\n",
    "x = block_proj(x)\n",
    "x = block_dropout(x)\n",
    "x += y\n",
    "# finish transformer\n",
    "x = transformer_norm(x)\n",
    "x = transformer_fc(x)\n",
    "assert x.shape == (B, T, vocab_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
