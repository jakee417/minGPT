{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32625032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e89b9",
   "metadata": {},
   "source": [
    "First run `chargpt.py` then this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5e66ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.utils import set_seed\n",
    "import torch\n",
    "from mingpt.model import GPT\n",
    "import projects.chargpt.chargpt as chargpt\n",
    "\n",
    "set_seed(3407)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88bdd125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 77358 characters, 61 unique.\n",
      "number of parameters: 2.71M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = chargpt.get_config()\n",
    "text = open(\"input.txt\", \"r\").read()\n",
    "train_dataset = chargpt.CharDataset(config.data, text)\n",
    "config.model.vocab_size = train_dataset.get_vocab_size()\n",
    "config.model.block_size = train_dataset.get_block_size()\n",
    "model = GPT(config.model).to(device)\n",
    "model.eval()\n",
    "weights = torch.load(\"out/chargpt/model.pt\")\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df416d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dd5e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = text[:15]\n",
    "encode = [train_dataset.stoi[s] for s in context]\n",
    "x = torch.tensor(encode, dtype=torch.long)[None, ...].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7c6b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will make B generations for the same prompt\n",
    "B = 5\n",
    "x = x.repeat(B, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bcb8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokens: torch.Tensor) -> str:\n",
    "    return ''.join([train_dataset.itos[int(i)] for i in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc8bd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, log_probs = model.generate(x, 500, temperature=1.0, do_sample=True, top_k=None, do_log_prob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb9328db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in \n",
      "----------------------------------------------------------------\n",
      "First Citizen:\n",
      "And topping all others in boasting.\n",
      "\n",
      "MENENIUS:\n",
      "This is strange now: do you two know how you are\n",
      "censured here in the city, I mean of us o' the\n",
      "right-hand file? do you?\n",
      "\n",
      "Both:\n",
      "Why, how are we censured?\n",
      "\n",
      "MENENIUS:\n",
      "Because you talk of pride now,--will you not be angry?\n",
      "\n",
      "Both:\n",
      "Well, well, sir, well.\n",
      "\n",
      "MENENIUS:\n",
      "Why, 'tis no great matter; for a very little thief of\n",
      "occasion will rob you of a great deal of patience:\n",
      "give your dispositions the reins, and be angry at\n",
      "your pleasures; at the least if you t\n",
      "----------------------------------------------------------------\n",
      "First Citizen:\n",
      "Ye're long about it.\n",
      "\n",
      "MENENIUS:\n",
      "Note me this, good friend;\n",
      "Your most grave belly was deliberate,\n",
      "Not rash like his accusers, and thus answer'd:\n",
      "'True is it, my incorporate friends,' quoth he,\n",
      "'That I receive the general food at first,\n",
      "Which you do live upon; and fit it it is,\n",
      "Because I am the store-house and the shop\n",
      "Of the whole body: but, if you do remember,\n",
      "I send it through the rivers of your blood,\n",
      "Even to the court, the heart, to the seat o' the brain;\n",
      "And, through the cranks and offices o\n",
      "----------------------------------------------------------------\n",
      "First Citizen:\n",
      "The price is to ask it kindly.\n",
      "\n",
      "CORIOLANUS:\n",
      "Kindly! Sir, I pray, let me ha't: I have wounds to\n",
      "show you, which shall be yours in private. Your\n",
      "good voice, sir; what say you?\n",
      "\n",
      "Second Citizen:\n",
      "You shall ha' it, worthy sir.\n",
      "\n",
      "CORIOLANUS:\n",
      "A match, sir. There's in all two worthy voices\n",
      "begged. I have your against the greater poll, and\n",
      "Your knees to them, not arms, must help. Alack,\n",
      "You are transported by calamity\n",
      "Thither where more attends you, and you slander\n",
      "The helms o' the state, who care for you \n",
      "----------------------------------------------------------------\n",
      "First Citizen:\n",
      "Very well; and could be content to give him good\n",
      "report fort, but that he pays himself with being proud.\n",
      "\n",
      "Second Citizen:\n",
      "Nay, but speak not maliciously.\n",
      "\n",
      "First Citizen:\n",
      "I say unto you, what he hath done famously, he did\n",
      "it to that end: though soft-conscienced men can be\n",
      "content to say it was for his country he did it to\n",
      "please his mother and to be partly proud; which he\n",
      "is, even till the altitude of his virtue.\n",
      "\n",
      "Second Citizen:\n",
      "What he cannot help in his nature, you account a\n",
      "vice in him. You m\n"
     ]
    }
   ],
   "source": [
    "print((\"\\n\" + \"-\" * 64 + \"\\n\").join([decode(i) for i in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cd9b980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9774, 0.9767, 0.9645, 0.9715, 0.9774], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = torch.exp(log_probs.mean(-1))\n",
    "perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
